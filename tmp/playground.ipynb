{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "NUM_EPOCHS = 50000\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_COLLOCATION = 10000\n",
    "PATIENCE = 100\n",
    "THRESHOLD = 1e-3\n",
    "EARLY_STOPPING_EPOCH = 1\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def numpy_to_tensor(array):\n",
    "    return torch.tensor(array, requires_grad=True, dtype=torch.float32).to(DEVICE).reshape(-1, 1)\n",
    "\n",
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)\n",
    "\n",
    "def generate_dataset(num_samples: int = NUM_SAMPLES):\n",
    "    \"\"\"Generate dataset of random multiple initial conditions and control actions\"\"\"\n",
    "    df = pd.DataFrame(columns=['t', 'X', 'S', 'V'])\n",
    "    df['X'] = np.random.uniform(0.1, 5)\n",
    "    df['S'] = np.random.uniform(5, 30)\n",
    "    df['V'] = np.random.uniform(0.5, 2)\n",
    "    df['F'] =  np.random.uniform(0.5, 2)\n",
    "    df['t'] = 0.0 # initial time\n",
    "    \n",
    "    t_train = numpy_to_tensor(df['t'].values)\n",
    "    X_train = numpy_to_tensor(df['X'].values)\n",
    "    S_train = numpy_to_tensor(df['S'].values)\n",
    "    V_train = numpy_to_tensor(df['V'].values)\n",
    "    F_train = numpy_to_tensor(df['F'].values)\n",
    "    \n",
    "    in_train = torch.cat([t_train, X_train, S_train, V_train, F_train], dim=1)\n",
    "    out_train = torch.cat([X_train, S_train, V_train], dim=1)\n",
    "    return in_train, out_train\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PINN, self).__init__()\n",
    "        self.input = nn.Linear(input_dim, 128)\n",
    "        self.fc1 = nn.Linear(128, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 128)\n",
    "        self.output = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input(x))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parameters\n",
    "T_START = 0\n",
    "T_END = 80\n",
    "TIME_RANGE = int(T_END - T_START) # Absolute time \n",
    "\n",
    "# Kinetic parameters\n",
    "MU_MAX = 0.20 # 1/h\n",
    "K_S = 1       # g/l\n",
    "Y_XS = 0.5    # g/g\n",
    "Y_PX = 0.2    # g/g\n",
    "S_F = 10      # g/l\n",
    "\n",
    "def loss_fn(net: nn.Module) -> torch.Tensor:\n",
    "    t_col = numpy_to_tensor(np.random.uniform(T_START, T_END, NUM_COLLOCATION))\n",
    "    X0_col = numpy_to_tensor(np.random.uniform(0.1, 5, NUM_COLLOCATION))\n",
    "    S0_col = numpy_to_tensor(np.random.uniform(5, 30, NUM_COLLOCATION))\n",
    "    V0_col = numpy_to_tensor(np.random.uniform(0.5, 2, NUM_COLLOCATION))\n",
    "    F_col = numpy_to_tensor(np.random.uniform(0.5, 2, NUM_COLLOCATION))\n",
    "    \n",
    "    u_col = torch.cat([t_col, X0_col, S0_col, V0_col, F_col], dim=1)\n",
    "\n",
    "    preds = net.forward(u_col)\n",
    "\n",
    "    X_pred = preds[:, 0].view(-1, 1)\n",
    "    S_pred = preds[:, 1].view(-1, 1)\n",
    "    V_pred = preds[:, 2].view(-1, 1)\n",
    "\n",
    "    dXdt_pred = grad(X_pred, t_col)[0]\n",
    "    dSdt_pred = grad(S_pred, t_col)[0]\n",
    "    dVdt_pred = grad(V_pred, t_col)[0]\n",
    "\n",
    "    mu = MU_MAX * S_pred / (K_S + S_pred)\n",
    "\n",
    "    error_dXdt = dXdt_pred - mu * X_pred + X_pred * F_col / V0_col\n",
    "    error_dSdt = dSdt_pred + mu * X_pred / Y_XS - F_col / V0_col * (S_F - S_pred)\n",
    "    error_dVdt = dVdt_pred - F_col\n",
    "    \n",
    "    error_ode = 1/3 * torch.mean(error_dXdt**2) + 1/3 * torch.mean(error_dSdt**2) + 1/3 * torch.mean(error_dVdt**2)\n",
    "\n",
    "    return error_ode\n",
    "\n",
    "def main(in_train: torch.Tensor, out_train: torch.Tensor, verbose: int = 100):\n",
    "    \n",
    "    net = PINN(input_dim=5, output_dim=3).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2500, gamma=0.7)\n",
    "\n",
    "    # Loss weights\n",
    "    w_data, w_ode, w_ic = 1.0, 1.0, 1.0\n",
    "\n",
    "    # Initialize early stopping variables\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    patience = PATIENCE\n",
    "    threshold = THRESHOLD\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        optimizer.zero_grad()\n",
    "        preds = net.forward(in_train)\n",
    "        X_pred = preds[:, 0].view(-1, 1)\n",
    "        S_pred = preds[:, 1].view(-1, 1)\n",
    "        V_pred = preds[:, 2].view(-1, 1)\n",
    "        loss_X = nn.MSELoss()(X_pred, out_train[:, 0].view(-1, 1))\n",
    "        loss_S = nn.MSELoss()(S_pred, out_train[:, 1].view(-1, 1))\n",
    "        loss_V = nn.MSELoss()(V_pred, out_train[:, 2].view(-1, 1))\n",
    "        loss_data = 0.33 * (loss_X + loss_S + loss_V)\n",
    "\n",
    "        loss_ode = loss_fn(net)\n",
    "\n",
    "        loss = w_data * loss_data + w_ode * loss_ode\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % verbose == 0:\n",
    "            print(f\"Epoch {epoch}, Loss_data: {loss_data.item():.4f}, Loss_ode: {loss_ode.item():.4f}\")\n",
    "            # Print the current learning rate of the optimizer\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(\"Current learning rate: \", param_group[\"lr\"])\n",
    "\n",
    "        if epoch >= EARLY_STOPPING_EPOCH:\n",
    "            if loss < best_loss - threshold:\n",
    "                best_loss = loss\n",
    "                best_model_weights = copy.deepcopy(net.state_dict())\n",
    "                patience = 1000\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    net.load_state_dict(best_model_weights)\n",
    "                    break\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train, out_train = generate_dataset(num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss_data: nan, Loss_ode: 56.1005\n",
      "Current learning rate:  0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 68\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(in_train, out_train, verbose)\u001b[0m\n\u001b[0;32m     65\u001b[0m loss_V \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(V_pred, out_train[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     66\u001b[0m loss_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.33\u001b[39m \u001b[38;5;241m*\u001b[39m (loss_X \u001b[38;5;241m+\u001b[39m loss_S \u001b[38;5;241m+\u001b[39m loss_V)\n\u001b[1;32m---> 68\u001b[0m loss_ode \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m w_data \u001b[38;5;241m*\u001b[39m loss_data \u001b[38;5;241m+\u001b[39m w_ode \u001b[38;5;241m*\u001b[39m loss_ode\n\u001b[0;32m     71\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m, in \u001b[0;36mloss_fn\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m     18\u001b[0m F_col \u001b[38;5;241m=\u001b[39m numpy_to_tensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m2\u001b[39m, NUM_COLLOCATION))\n\u001b[0;32m     20\u001b[0m u_col \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([t_col, X0_col, S0_col, V0_col, F_col], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m preds[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m S_pred \u001b[38;5;241m=\u001b[39m preds[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 56\u001b[0m, in \u001b[0;36mPINN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput(x))\n\u001b[0;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[1;32m---> 56\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x)\n",
      "File \u001b[1;32mc:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mexis\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = main(in_train, out_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
